{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Config File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/data.csv',\n",
       " 'data_set_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_columns_path': 'data/output/input_columns.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'index_column': 'Unnamed: 0',\n",
       " 'output_column': 'SeriousDlqin2yrs',\n",
       " 'seed': 42,\n",
       " 'test_size': 0.2,\n",
       " 'clean_late_col': 'NumberOfTimes90DaysLate',\n",
       " 'clean_late_val': 96,\n",
       " 'clean_unsecure_col': 'RevolvingUtilizationOfUnsecuredLines',\n",
       " 'constant_imputer_col': 'NumberOfDependents',\n",
       " 'constant_imputer_path': 'data/output/constant_imputer.pkl',\n",
       " 'constant_imputer_val': 0.0,\n",
       " 'median_imputer_col': 'MonthlyIncome',\n",
       " 'median_imputer_path': 'data/output/median_imputer.pkl',\n",
       " 'standardizer_path': 'data/output/standardizer.pkl',\n",
       " 'preprocessor_path': 'data/output/preprocessor.pkl',\n",
       " 'train_clean_path': ['data/output/X_train_clean.pkl',\n",
       "  'data/output/y_train_clean.pkl'],\n",
       " 'valid_clean_path': ['data/output/X_valid_clean.pkl',\n",
       "  'data/output/y_valid_clean.pkl'],\n",
       " 'test_clean_path': ['data/output/X_test_clean.pkl',\n",
       "  'data/output/y_test_clean.pkl'],\n",
       " 'print_debug': True,\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model of Choice\n",
    "- KNN\n",
    "- Decision Tree\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_param():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    knn_params = {\n",
    "        'n_neighbors': [50, 100, 200],\n",
    "    }\n",
    "    \n",
    "    lgr_params = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1],\n",
    "        'max_iter': [100, 300, 500]\n",
    "    }\n",
    "\n",
    "    xgb_params = {\n",
    "        'n_estimators': [5, 10, 25, 50]\n",
    "    }\n",
    "\n",
    "    # Create model params\n",
    "    list_of_param = {\n",
    "        'KNeighborsClassifier': knn_params,\n",
    "        'LogisticRegression': lgr_params,\n",
    "        'XGBClassifier': xgb_params\n",
    "    }\n",
    "\n",
    "    return list_of_param\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    print(\"Creating model objects\")\n",
    "\n",
    "    # Create model objects\n",
    "    knn = KNeighborsClassifier()\n",
    "    lgr = LogisticRegression(solver='liblinear')\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        {'model_name': knn.__class__.__name__, 'model_object': knn},\n",
    "        {'model_name': lgr.__class__.__name__, 'model_object': lgr},\n",
    "        {'model_name': xgb.__class__.__name__, 'model_object': xgb}\n",
    "    ]\n",
    "\n",
    "    return list_of_model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load dataset\n",
    "    X_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][0])\n",
    "    y_train = utils.pickle_load(CONFIG_DATA['train_clean_path'][1])\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][0])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][1])\n",
    "    \n",
    "    # Create list of params & models\n",
    "    list_of_param = create_model_param()\n",
    "    list_of_model = create_model_object()\n",
    "\n",
    "    # List of trained model\n",
    "    list_of_tuned_model = {}\n",
    "\n",
    "    # Train model\n",
    "    for base_model in list_of_model:\n",
    "        # Current condition\n",
    "        model_name = base_model['model_name']\n",
    "        model_obj = copy.deepcopy(base_model['model_object'])\n",
    "        model_param = list_of_param[model_name]\n",
    "\n",
    "        # Debug message\n",
    "        print('Training model :', model_name)\n",
    "\n",
    "        # Create model object\n",
    "        model = RandomizedSearchCV(estimator = model_obj,\n",
    "                                   param_distributions = model_param,\n",
    "                                   n_iter=5,\n",
    "                                   cv = 5,\n",
    "                                   random_state = 123,\n",
    "                                   n_jobs=1,\n",
    "                                   verbose=10,\n",
    "                                   scoring = 'roc_auc')\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # Get score\n",
    "        train_score = roc_auc_score(y_train, y_pred_proba_train)\n",
    "        valid_score = roc_auc_score(y_valid, y_pred_proba_valid)\n",
    "\n",
    "        # Append\n",
    "        list_of_tuned_model[model_name] = {\n",
    "            'model': model,\n",
    "            'train_auc': train_score,\n",
    "            'valid_auc': valid_score,\n",
    "            'best_params': model.best_params_\n",
    "        }\n",
    "\n",
    "        print(\"Done training\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(list_of_param, CONFIG_DATA['list_of_param_path'])\n",
    "    utils.pickle_dump(list_of_model, CONFIG_DATA['list_of_model_path'])\n",
    "    utils.pickle_dump(list_of_tuned_model, CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    if return_file:\n",
    "        return list_of_param, list_of_model, list_of_tuned_model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : KNeighborsClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_neighbors=50..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cahya_pacmann/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=5. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/3] END ...............n_neighbors=50;, score=0.858 total time=   0.4s\n",
      "[CV 2/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 2/5; 1/3] END ...............n_neighbors=50;, score=0.853 total time=   0.3s\n",
      "[CV 3/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 3/5; 1/3] END ...............n_neighbors=50;, score=0.846 total time=   0.4s\n",
      "[CV 4/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 4/5; 1/3] END ...............n_neighbors=50;, score=0.851 total time=   0.3s\n",
      "[CV 5/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 5/5; 1/3] END ...............n_neighbors=50;, score=0.856 total time=   0.3s\n",
      "[CV 1/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 1/5; 2/3] END ..............n_neighbors=100;, score=0.858 total time=   0.3s\n",
      "[CV 2/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 2/5; 2/3] END ..............n_neighbors=100;, score=0.855 total time=   0.3s\n",
      "[CV 3/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 3/5; 2/3] END ..............n_neighbors=100;, score=0.847 total time=   0.4s\n",
      "[CV 4/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 4/5; 2/3] END ..............n_neighbors=100;, score=0.852 total time=   0.6s\n",
      "[CV 5/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 5/5; 2/3] END ..............n_neighbors=100;, score=0.856 total time=   0.6s\n",
      "[CV 1/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 1/5; 3/3] END ..............n_neighbors=200;, score=0.857 total time=   0.8s\n",
      "[CV 2/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 2/5; 3/3] END ..............n_neighbors=200;, score=0.853 total time=   0.6s\n",
      "[CV 3/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 3/5; 3/3] END ..............n_neighbors=200;, score=0.844 total time=   1.0s\n",
      "[CV 4/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 4/5; 3/3] END ..............n_neighbors=200;, score=0.852 total time=   0.9s\n",
      "[CV 5/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 5/5; 3/3] END ..............n_neighbors=200;, score=0.856 total time=   0.8s\n",
      "Done training\n",
      "\n",
      "Training model : LogisticRegression\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 1/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 2/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 3/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 4/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 1/5] START C=0.01, max_iter=500, penalty=l2............................\n",
      "[CV 5/5; 1/5] END C=0.01, max_iter=500, penalty=l2;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 1/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 2/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 3/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 4/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 2/5] START C=0.01, max_iter=100, penalty=l1............................\n",
      "[CV 5/5; 2/5] END C=0.01, max_iter=100, penalty=l1;, score=0.852 total time=   0.0s\n",
      "[CV 1/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 1/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.857 total time=   0.0s\n",
      "[CV 2/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 2/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.853 total time=   0.0s\n",
      "[CV 3/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 3/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.843 total time=   0.0s\n",
      "[CV 4/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 4/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 5/5; 3/5] START C=0.01, max_iter=500, penalty=l1............................\n",
      "[CV 5/5; 3/5] END C=0.01, max_iter=500, penalty=l1;, score=0.852 total time=   0.0s\n",
      "[CV 1/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 1/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.856 total time=   0.0s\n",
      "[CV 2/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 2/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 3/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.848 total time=   0.0s\n",
      "[CV 4/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 4/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 4/5] START C=0.1, max_iter=300, penalty=l2.............................\n",
      "[CV 5/5; 4/5] END C=0.1, max_iter=300, penalty=l2;, score=0.855 total time=   0.0s\n",
      "[CV 1/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 1/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.856 total time=   0.0s\n",
      "[CV 2/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 2/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.854 total time=   0.0s\n",
      "[CV 3/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 3/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.847 total time=   0.0s\n",
      "[CV 4/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 4/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.849 total time=   0.0s\n",
      "[CV 5/5; 5/5] START C=0.1, max_iter=300, penalty=l1.............................\n",
      "[CV 5/5; 5/5] END C=0.1, max_iter=300, penalty=l1;, score=0.854 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : XGBClassifier\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 1/5; 1/4] END ...............n_estimators=5;, score=0.859 total time=   0.1s\n",
      "[CV 2/5; 1/4] START n_estimators=5..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cahya_pacmann/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/4] END ...............n_estimators=5;, score=0.851 total time=   0.2s\n",
      "[CV 3/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 3/5; 1/4] END ...............n_estimators=5;, score=0.846 total time=   0.1s\n",
      "[CV 4/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 4/5; 1/4] END ...............n_estimators=5;, score=0.849 total time=   0.2s\n",
      "[CV 5/5; 1/4] START n_estimators=5..............................................\n",
      "[CV 5/5; 1/4] END ...............n_estimators=5;, score=0.851 total time=   0.1s\n",
      "[CV 1/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 1/5; 2/4] END ..............n_estimators=10;, score=0.858 total time=   0.5s\n",
      "[CV 2/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 2/5; 2/4] END ..............n_estimators=10;, score=0.854 total time=   0.2s\n",
      "[CV 3/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 3/5; 2/4] END ..............n_estimators=10;, score=0.850 total time=   0.2s\n",
      "[CV 4/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 4/5; 2/4] END ..............n_estimators=10;, score=0.851 total time=   0.1s\n",
      "[CV 5/5; 2/4] START n_estimators=10.............................................\n",
      "[CV 5/5; 2/4] END ..............n_estimators=10;, score=0.854 total time=   0.4s\n",
      "[CV 1/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 1/5; 3/4] END ..............n_estimators=25;, score=0.858 total time=   0.4s\n",
      "[CV 2/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 2/5; 3/4] END ..............n_estimators=25;, score=0.850 total time=   0.5s\n",
      "[CV 3/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 3/5; 3/4] END ..............n_estimators=25;, score=0.848 total time=   0.5s\n",
      "[CV 4/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 4/5; 3/4] END ..............n_estimators=25;, score=0.848 total time=   0.5s\n",
      "[CV 5/5; 3/4] START n_estimators=25.............................................\n",
      "[CV 5/5; 3/4] END ..............n_estimators=25;, score=0.854 total time=   0.5s\n",
      "[CV 1/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 1/5; 4/4] END ..............n_estimators=50;, score=0.855 total time=   0.7s\n",
      "[CV 2/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 2/5; 4/4] END ..............n_estimators=50;, score=0.845 total time=   0.8s\n",
      "[CV 3/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 3/5; 4/4] END ..............n_estimators=50;, score=0.845 total time=   0.7s\n",
      "[CV 4/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 4/5; 4/4] END ..............n_estimators=50;, score=0.845 total time=   0.8s\n",
      "[CV 5/5; 4/4] START n_estimators=50.............................................\n",
      "[CV 5/5; 4/4] END ..............n_estimators=50;, score=0.850 total time=   0.6s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'model': RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(), n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_neighbors': [50, 100, 200]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8602520227232879,\n",
       "  'valid_auc': 0.8630241585805997,\n",
       "  'best_params': {'n_neighbors': 100}},\n",
       " 'LogisticRegression': {'model': RandomizedSearchCV(cv=5, estimator=LogisticRegression(solver='liblinear'),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'C': [0.01, 0.1],\n",
       "                                          'max_iter': [100, 300, 500],\n",
       "                                          'penalty': ['l1', 'l2']},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8526284453004676,\n",
       "  'valid_auc': 0.8558417597656988,\n",
       "  'best_params': {'penalty': 'l2', 'max_iter': 500, 'C': 0.01}},\n",
       " 'XGBClassifier': {'model': RandomizedSearchCV(cv=5,\n",
       "                     estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                             callbacks=None,\n",
       "                                             colsample_bylevel=None,\n",
       "                                             colsample_bynode=None,\n",
       "                                             colsample_bytree=None,\n",
       "                                             early_stopping_rounds=None,\n",
       "                                             enable_categorical=False,\n",
       "                                             eval_metric=None, feature_types=None,\n",
       "                                             gamma=None, gpu_id=None,\n",
       "                                             grow_policy=None,\n",
       "                                             importance_type=None,\n",
       "                                             interaction_constraints=None,\n",
       "                                             learning_rate...\n",
       "                                             max_cat_threshold=None,\n",
       "                                             max_cat_to_onehot=None,\n",
       "                                             max_delta_step=None, max_depth=None,\n",
       "                                             max_leaves=None,\n",
       "                                             min_child_weight=None, missing=nan,\n",
       "                                             monotone_constraints=None,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             num_parallel_tree=None,\n",
       "                                             predictor=None, random_state=None, ...),\n",
       "                     n_iter=5, n_jobs=1,\n",
       "                     param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                     random_state=123, scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8823169617515427,\n",
       "  'valid_auc': 0.8654187830374896,\n",
       "  'best_params': {'n_estimators': 10}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tuned_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(return_file=True):\n",
    "    \"\"\"Function to get the best model\"\"\"\n",
    "    # Load tuned model\n",
    "    list_of_tuned_model = utils.pickle_load(CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    # Get the best model\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_performance = -99999\n",
    "    best_model_param = None\n",
    "\n",
    "    for model_name, model in list_of_tuned_model.items():\n",
    "        if model['valid_auc'] > best_performance:\n",
    "            best_model_name = model_name\n",
    "            best_model = model['model']\n",
    "            best_performance = model['valid_auc']\n",
    "            best_model_param = model['best_params']\n",
    "\n",
    "    # Dump the best model\n",
    "    utils.pickle_dump(best_model, CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Print\n",
    "    print('=============================================')\n",
    "    print('Best model        :', best_model_name)\n",
    "    print('Metric score      :', best_performance)\n",
    "    print('Best model params :', best_model_param)\n",
    "    print('=============================================')\n",
    "\n",
    "    if return_file:\n",
    "        return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best model        : XGBClassifier\n",
      "Metric score      : 0.8654187830374896\n",
      "Best model params : {'n_estimators': 10}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "best_model = get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={&#x27;n_estimators&#x27;: [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring=&#x27;roc_auc&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={&#x27;n_estimators&#x27;: [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring=&#x27;roc_auc&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                           max_cat_threshold=None,\n",
       "                                           max_cat_to_onehot=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_iter=5, n_jobs=1,\n",
       "                   param_distributions={'n_estimators': [5, 10, 25, 50]},\n",
       "                   random_state=123, scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_threshold(return_file=True):\n",
    "    \"\"\"Function to tune & get the best decision threshold\"\"\"\n",
    "    # Load data & model\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][0])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'][1])\n",
    "    best_model = utils.pickle_load(CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Get the proba pred\n",
    "    y_pred_proba = best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Initialize\n",
    "    metric_threshold = pd.Series([])\n",
    "    \n",
    "    # Optimize\n",
    "    for threshold_value in THRESHOLD:\n",
    "        # Get predictions\n",
    "        y_pred = (y_pred_proba >= threshold_value).astype(int)\n",
    "\n",
    "        # Get the F1 score\n",
    "        metric_score = f1_score(y_valid, y_pred, average='macro')\n",
    "\n",
    "        # Add to the storage\n",
    "        metric_threshold[metric_score] = threshold_value\n",
    "\n",
    "    # Find the threshold @max metric score\n",
    "    metric_score_max_index = metric_threshold.index.max()\n",
    "    best_threshold = metric_threshold[metric_score_max_index]\n",
    "    print('=============================================')\n",
    "    print('Best threshold :', best_threshold)\n",
    "    print('Metric score   :', metric_score_max_index)\n",
    "    print('=============================================')\n",
    "    \n",
    "    # Dump file\n",
    "    utils.pickle_dump(best_threshold, CONFIG_DATA['best_threshold_path'])\n",
    "\n",
    "    if return_file:\n",
    "        return best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15938/1872309259.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  metric_threshold = pd.Series([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best threshold : 0.797979797979798\n",
      "Metric score   : 0.7043463245931029\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.797979797979798"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
